{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "import time\n",
    "\n",
    "\n",
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        func(*args, **kwargs)\n",
    "        print('Completed setting {:.3f}'.format(time.time() - start_time))\n",
    "        return\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class InitialAnalysis:\n",
    "    def __init__(self, *kwargs):\n",
    "        pass\n",
    "    \n",
    "    @timeit\n",
    "    def setting(self):\n",
    "        print('Initializing analysis environment...')\n",
    "        self.loadling_libraries()\n",
    "        print('* current working directory: {}'.format(os.getcwd()))\n",
    "        for name in glob.glob('input/*'):\n",
    "            print(name)\n",
    "#         file_name = input()\n",
    "        \n",
    "        print('pandas {}, numpy {}, '.format(pd.__version__, np.__version__))\n",
    "        import sys\n",
    "        print('Python: {}'.format(sys.version))\n",
    "        import numpy as np\n",
    "        \n",
    "    \n",
    "    def _set_pandas(self):\n",
    "        pd.options.display.max_columns = 50\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _set_matplotlib(self):\n",
    "        if platform.system() == 'Windows':\n",
    "            font_name = font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "            rc('font', family=font_name)\n",
    "        else:\n",
    "            rc('font', family='AppleGothic')\n",
    "        \n",
    "#         %matplotlib inline\n",
    "        %matplotlib notebook\n",
    "        sns.set_style(style='white')\n",
    "        plt.rcParams['axes.unicode_minus'] = kwargs.get('unicode_minus')\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def _set_jupyter(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def check_datatypes(self):\n",
    "        pass\n",
    "    \n",
    "    def check_missing(self):\n",
    "        df.isnull().any()\n",
    "        df.isnull().sum()\n",
    "        df.isnull().sum()[df.isnull().sum()].to_frame()\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def loadling_libraries(self):\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        # import parguet,\n",
    "        import pickle\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import glob\n",
    "        import os\n",
    "        import platform\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Fixed random seed\n",
    "# max columns\n",
    "# display.\n",
    "# plot styles\n",
    "# Handling Korean\n",
    "# Current path\n",
    "\n",
    "\n",
    "# input data path\n",
    "\n",
    "# loading labraries\n",
    "# \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Initializing analysis environment...\n",
      "* current working directory: /Users/unerue/Dropbox/github/snippet/examples\n",
      "input/test.csv\n",
      "input/train.csv\n",
      "pandas 0.24.2, numpy 1.16.4, \n",
      "Completed setting 0.001\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d35bb0ae56f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mInitialAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from analysis import InitialAnalysis\n",
    "\n",
    "\n",
    "InitialAnalysis().setting()\n",
    "\n",
    "np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "InitialAnalysis().setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(), cmap='cubehelix', cbar=False, yticklabels=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm_notebook\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "sns.set_style(style='white')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "# Show all columns\n",
    "pd.options.display.max_columns = 50\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    rc('font', family='AppleGothic')\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('input/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Survived']].copy()\n",
    "cols = train.select_dtypes(include='object').columns\n",
    "print(cols)\n",
    "\n",
    "train[cols] = train[cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train[cols].copy()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cols] = train[cols].apply(lambda x: x.cat.codes)\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['Survived'], axis=1).copy()\n",
    "y = train['Survived'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "rf.score(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select_dtypes(include='category').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby(by=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names):\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, one_hot=False):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.select_dtypes(include='category').copy()\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if X.isnull().values.any():\n",
    "            raise ValueError('dataframe has the missing values.')\n",
    "        \n",
    "        self._label_encoders = [LabelEncoder() for _ in range(n_features)]\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders[i]\n",
    "            le.fit(X.iloc[:, i])\n",
    "            \n",
    "        self._categories = [le.classes_ for le in self._label_encoders]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.select_dtypes(include='category').copy()\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X.iloc[:, i], self._categories[i])\n",
    "            \n",
    "            if not np.all(valid_mask):\n",
    "                raise ValueError('')\n",
    "            else:\n",
    "                X_mask[:, i] = valid_mask\n",
    "                X.iloc[:, i][~valid_mask] = self._categories[i][0]\n",
    "                X.iloc[:, i] = self._label_encoders[i].transform(X.iloc[:, i])\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = Pipeline([\n",
    "                ('selector', FeatureSelector(['Sex'])),\n",
    "                ('test', CategoricalEncoder())\n",
    "            ])\n",
    "\n",
    "pipe2 = Pipeline([\n",
    "                ('selector', FeatureSelector(['Embarked'])),\n",
    "                ('test', )\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "tt = pipe1.fit_transform(train.dropna())\n",
    "tt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "\n",
    "pipeline = Pipeline([pipe1, pipe2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text = Pipeline([\n",
    "                ('selector', FeatureSelector(['Sex', 'Embarked', 'Cabin'])),\n",
    "                ('test', CategoricalEncoder())\n",
    "            ])\n",
    "\n",
    "aa = text.fit_transform(train.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "text = Pipeline([\n",
    "                ('selector', FeatureSelector(['Sex', 'Embarked', 'Cabin'])),\n",
    "                ('test', LabelEncoder())\n",
    "            ])\n",
    "\n",
    "aa = text.fit_transform(train.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['Sex', 'Embarked']].dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked'].dropna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']\n",
    "cat_attribs = ['Sex', 'Cabin', 'Embarked']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', LabelEncoder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num_pipeline\", num_pipeline, num_attribs),\n",
    "        (\"cat_encoder\", cat_pipeline, cat_attribs),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from future_encoders import ColumnTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = ['Age', 'Fare']\n",
    "cat_attribs = ['Sex']\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_attribs),\n",
    "        (\"cat\", LabelEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "# aaa = full_pipeline.fit_transform(train)\n",
    "# aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy import sparse\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.select_dtypes(include='category').copy()\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        if X.isnull().values.any():\n",
    "            msg = 'dataframe has the missing values.'\n",
    "            raise ValueError(msg)\n",
    "        \n",
    "        self._label_encoders = [LabelEncoder() for _ in range(n_features)]\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders[i]\n",
    "            le.fit(X.iloc[:, i])\n",
    "            \n",
    "        self._categories = [le.classes_ for le in self._label_encoders]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.select_dtypes(include='category').copy()\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X.iloc[:, i], self._categories[i])\n",
    "            \n",
    "            if not np.all(valid_mask):\n",
    "                raise ValueError('')\n",
    "            else:\n",
    "                X_mask[:, i] = valid_mask\n",
    "                X.iloc[:, i][~valid_mask] = self._categories[i][0]\n",
    "                X.iloc[:, i] = self._label_encoders[i].transform(X.iloc[:, i])\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = np.in1d(test.iloc[:, 0], ['male'])\n",
    "print(valid[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[:, 0][~valid].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = CategoricalEncoder()\n",
    "encoder.fit(test.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.copy()\n",
    "test1['Sex'] = test1['Sex'].astype(np.object)\n",
    "test1.iloc[1, 0] = 'test'\n",
    "test1['Sex'] = test1['Sex'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.transform(test1.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "\n",
    "        self._label_encoders = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders_[i]\n",
    "            Xi = X[:, i]\n",
    "            if self.categories == 'auto':\n",
    "                le.fit(Xi)\n",
    "            else:\n",
    "                valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(Xi[~valid_mask])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during fit\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform X using one-hot encoding.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to encode.\n",
    "        Returns\n",
    "        -------\n",
    "        X_out : sparse matrix or a 2-d array\n",
    "            Transformed input.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_int = np.zeros_like(X, dtype=np.int)\n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == 'error':\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                           \" during transform\".format(diff, i))\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    # Set the problematic rows to an acceptable value and\n",
    "                    # continue `The rows are marked `X_mask` and will be\n",
    "                    # removed later.\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "\n",
    "        if self.encoding == 'ordinal':\n",
    "            return X_int.astype(self.dtype, copy=False)\n",
    "\n",
    "        mask = X_mask.ravel()\n",
    "        n_values = [cats.shape[0] for cats in self.categories_]\n",
    "        n_values = np.array([0] + n_values)\n",
    "        indices = np.cumsum(n_values)\n",
    "\n",
    "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                n_features)[mask]\n",
    "        data = np.ones(n_samples * n_features)[mask]\n",
    "\n",
    "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                shape=(n_samples, indices[-1]),\n",
    "                                dtype=self.dtype).tocsr()\n",
    "        if self.encoding == 'onehot-dense':\n",
    "            return out.toarray()\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_chart(train_scores, test_scores, best_param_train, best_param_test, \n",
    "               best_score_train, best_score_test, n_iter, title, xlabel, ax):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ax.plot(train_scores, 'r.--', label='Validation scores')\n",
    "    ax.plot(test_scores, 'b.-', label='Test scores')\n",
    "\n",
    "    ax.plot([best_param_train, best_param_train], [best_score_train, max(ax.get_ylim())], 'k--')\n",
    "    ax.plot([1, n_iter], [best_score_train, best_score_train], 'k--')\n",
    "    ax.plot(best_param_train, best_score_train, 'k.')\n",
    "\n",
    "    ax.plot([best_param_test, best_param_test], [best_score_test, max(ax.get_ylim())], 'k--')\n",
    "    ax.plot([1, n_iter], [best_score_test, best_score_test], 'k--')\n",
    "    ax.plot(best_param_test, best_score_test, 'k.')\n",
    "\n",
    "    # ax.text(best_n_estimators, min_error*1.05, \"Minimum\", ha=\"center\", fontsize=14)\n",
    "    # ax.axis([-1, 201, 0.34, 0.41])\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.grid()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sm.datasets.anes96.load_pandas().data\n",
    "cols = [col for col in df.columns.tolist() if col != 'logpopul']\n",
    "df[cols] = df[cols].astype(np.int64)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barchart using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_barchart(df, ax=None, sort=False, horizon=False, legend=False, **kwargs):\n",
    "    \"\"\"Customized bar chart\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    'edgecolor' : string default \"dict\"\n",
    "    \"\"\"\n",
    "    \n",
    "    plot_args = {'edgecolor': 'black', 'linewidth': 0.7, 'width': 0.8, 'colormap': None}\n",
    "    legend_args = {'loc': 'best', 'ncol': 1, 'borderpad': 0.8, 'prop': {'size': 8}}\n",
    "    tick_args = {'axis': 'x', 'rotation': None}\n",
    "    \n",
    "    if kwargs:\n",
    "        for key, value in kwargs['kwargs'].items():\n",
    "            if key in plot_args.keys():\n",
    "                plot_args[key] = value\n",
    "                \n",
    "            elif key in legend_args.keys():\n",
    "                legend_args[key] = value\n",
    "                \n",
    "            elif key in tick_args.keys():\n",
    "                tick_args[key] = value\n",
    "\n",
    "    if horizon:\n",
    "        horizon = 'barh'\n",
    "        axis = 'x'\n",
    "    else:\n",
    "        horizon = 'bar'\n",
    "        axis = 'y'\n",
    "\n",
    "    if sort:\n",
    "        temp.sort_index(inplace=True)\n",
    "        \n",
    "    lgd_lw = plot_args.get('linewidth')\n",
    "    temp.plot(kind=horizon, ax=ax, **plot_args)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis=axis, linestyle='--')\n",
    "       \n",
    "    if legend:\n",
    "        lgd = ax.legend(frameon=True, framealpha=1, shadow=False, fancybox=False,  \n",
    "                        edgecolor='black', **legend_args)\n",
    "        lgd.get_frame().set_linewidth(lgd_lw)\n",
    "    ax.tick_params(axis=tick_args.pop('axis'), **tick_args)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df['TVnews'].value_counts()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette('colorblind')\n",
    "\n",
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_barchart(df, ax=ax, sort=True, horizon=False, kwargs={'edgecolor': 'black', 'width': 0.8, 'rotation': 0})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_barchart(df, ax=ax, sort=True, horizon=False, kwargs={'edgecolor': 'black', 'width': 0.8, 'rotation': 0})\n",
    "\n",
    "# Add labels\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    x = p.get_x()\n",
    "    ax.text(x=x+0.2, y=height+2, s=f'{height}', fontsize=10)\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.pivot_table(values='TVnews', index='PID', columns='vote', aggfunc='count')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_barchart(df, ax=ax, sort=True, horizon=False, legend=True, kwargs={'linewidth': 0.7, 'ncol': 2, 'width': 0.9})\n",
    "\n",
    "# Add labels\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    x = p.get_x()\n",
    "    ax.text(x=x+0.05, y=height+0.5, s=f'{height}', fontsize=10)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_barchart(df, ax=ax, sort=True, horizon=True, legend=True, kwargs={'linewidth': 0.7, 'ncol': 2, 'width': 0.9})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_barchart(df, ax=ax, sort=True, horizon=True, legend=True, kwargs={'linewidth': 0.7, 'ncol': 2, 'width': 0.9})\n",
    "\n",
    "# Add labels\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    y = p.get_y()\n",
    "    ax.text(x=width+0.5, y=y+0.12, s=f'{width}', ha='left', fontsize=10)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxplot(df, x, y, hue=None, col=None, ax=None, **kwargs):\n",
    "    plot_args = {'linewidth': 1.2, 'width': 0.8}\n",
    "    legend_args = {'loc': 'best', 'ncol': 1, 'borderpad': 0.8, 'prop': {'size': 8}}\n",
    "    \n",
    "    if kwargs:\n",
    "        for key, value in kwargs['kwargs'].items():\n",
    "            if key in plot_args.keys():\n",
    "                plot_args[key] = value\n",
    "                \n",
    "            elif key in legend_args.keys():\n",
    "                legend_args[key] = value\n",
    "                \n",
    "            elif key in tick_args.keys():\n",
    "                tick_args[key] = value\n",
    "       \n",
    "    legend = False\n",
    "    if hue:\n",
    "        legend = True\n",
    "    \n",
    "    lgd_lw = plot_args.get('linewidth') * 0.7\n",
    "    sns.boxplot(x=x, y=y, hue=hue, data=df, saturation=1, \n",
    "                linewidth=plot_args.pop('linewidth'), ax=ax, **plot_args)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.grid(axis='y', linestyle='--')\n",
    "\n",
    "    if legend:\n",
    "        lgd = ax.legend(frameon=True, framealpha=1, shadow=False, fancybox=False,  \n",
    "                        edgecolor='black', **legend_args)\n",
    "        lgd.get_frame().set_linewidth(lgd_lw)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_boxplot(df, x='PID', y='age', ax=ax, kwargs={'width': 0.5})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_boxplot(df, x='PID', y='age', hue='vote', ax=ax, kwargs={'ncol': 2})\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def draw_confusion_matrix(y_true, y_pred, ax=None):\n",
    "    \"\"\"draw_confusion_matrix\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    im = ax.imshow(normalized_cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, fraction=0.025, ax=ax)\n",
    "    \n",
    "    classes = ['C{}'.format(c+1) for c in range(len(cm))]\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i+0.05, '{}\\n({:.2f})'.format(cm[i, j], normalized_cm[i,j]), \n",
    "                horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
    "    ax.set_ylabel('True classes')\n",
    "    ax.set_xlabel('Predicted classes')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "clf = LogisticRegression(multi_class='auto', solver='lbfgs', max_iter=1000).fit(data.data, data.target)\n",
    "y_pred = clf.predict(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=100)\n",
    "ax = plt.axes()\n",
    "\n",
    "draw_confusion_matrix(data.target, y_pred, ax=ax)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# fig.savefig('confusion.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
